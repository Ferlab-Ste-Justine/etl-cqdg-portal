import bio.ferlab.datalake.commons.config.Format.{AVRO, PARQUET}
import bio.ferlab.datalake.commons.config.LoadType.OverWrite
import bio.ferlab.datalake.commons.config.{DatasetConf, StorageConf}
import bio.ferlab.datalake.commons.file.FileSystemType.S3
import utils.StartMinioServer.BUCKETNAME

import scala.collection.immutable

package object etl {

  val storage = "storage"

  val STORAGES: List[StorageConf] = List(
    StorageConf(filesystem = S3, id = "storage", path = s"s3a://$BUCKETNAME")
  )

  val SOURCES: List[DatasetConf] = List(
    DatasetConf(
      format = AVRO,
      id = "raw_patient",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/fhir/patient",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = PARQUET,
      id = "normalized_patient",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/normalized/patient",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "overwriteSchema" -> "true",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = AVRO,
      id = "raw_diagnosis",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/fhir/condition",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = PARQUET,
      id = "normalized_diagnosis",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/normalized/diagnosis",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "overwriteSchema" -> "true",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
//    DatasetConf(
//      format = AVRO,
//      id = "raw_cause_of_death",
//      keys = List.empty,
//      loadtype = OverWrite,
//      partitionby = List("study_id", "release_id"),
//      path = "/fhir/observation",
//      readoptions = Map.empty,
//      storageid = storage,
//      writeoptions = Map(
//        "created_on_column" -> "created_on",
//        "is_current_column" -> "is_current",
//        "updated_on_column" -> "updated_on",
//        "valid_from_column" -> "valid_from",
//        "valid_to_column" -> "valid_to",
//      ),
//    ),
//    DatasetConf(
//      format = PARQUET,
//      id = "normalized_cause_of_death",
//      keys = List.empty,
//      loadtype = OverWrite,
//      partitionby = List("study_id", "release_id"),
//      path = "/normalized/cause_of_death",
//      readoptions = Map.empty,
//      storageid = storage,
//      writeoptions = Map(
//        "created_on_column" -> "created_on",
//        "is_current_column" -> "is_current",
//        "overwriteSchema" -> "true",
//        "updated_on_column" -> "updated_on",
//        "valid_from_column" -> "valid_from",
//        "valid_to_column" -> "valid_to",
//      ),
//    ),
    DatasetConf(
      format = AVRO,
      id = "raw_disease_status",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/fhir/observation",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = PARQUET,
      id = "normalized_disease_status",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/normalized/disease_status",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "overwriteSchema" -> "true",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = AVRO,
      id = "raw_phenotype",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/fhir/observation",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = PARQUET,
      id = "normalized_phenotype",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/normalized/phenotype",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "overwriteSchema" -> "true",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = AVRO,
      id = "raw_biospecimen",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/fhir/specimen",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = PARQUET,
      id = "normalized_biospecimen",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/normalized/biospecimen",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "overwriteSchema" -> "true",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = AVRO,
      id = "raw_sample_registration",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id","release_id"),
      path = "/fhir/specimen",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = PARQUET,
      id = "normalized_sample_registration",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id","release_id"),
      path = "/normalized/sample_registration",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "overwriteSchema" -> "true",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = AVRO,
      id = "raw_research_study",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/fhir/researchstudy",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = PARQUET,
      id = "normalized_research_study",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/normalized/research_study",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "overwriteSchema" -> "true",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = AVRO,
      id = "raw_document_reference",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/fhir/documentreference",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = PARQUET,
      id = "normalized_document_reference",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/normalized/document_reference",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "overwriteSchema" -> "true",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = AVRO,
      id = "raw_family_relationship",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/fhir/observation",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = PARQUET,
      id = "normalized_family_relationship",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/normalized/family_relationship",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "overwriteSchema" -> "true",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = AVRO,
      id = "raw_tumor_normal_designation",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/fhir/observation",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = PARQUET,
      id = "normalized_tumor_normal_designation",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/normalized/tumor_normal_designation",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "overwriteSchema" -> "true",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = AVRO,
      id = "raw_group",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/fhir/group",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = PARQUET,
      id = "normalized_group",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/normalized/group",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "overwriteSchema" -> "true",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = AVRO,
      id = "raw_task",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/fhir/task",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
    DatasetConf(
      format = PARQUET,
      id = "normalized_task",
      keys = List.empty,
      loadtype = OverWrite,
      partitionby = List("study_id", "release_id"),
      path = "/normalized/task",
      readoptions = Map.empty,
      storageid = storage,
      writeoptions = Map(
        "created_on_column" -> "created_on",
        "is_current_column" -> "is_current",
        "overwriteSchema" -> "true",
        "updated_on_column" -> "updated_on",
        "valid_from_column" -> "valid_from",
        "valid_to_column" -> "valid_to",
      ),
    ),
  )
}
